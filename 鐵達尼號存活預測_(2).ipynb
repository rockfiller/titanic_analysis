{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6LE0kP029HUvrvrrYsNBh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rockfiller/titanic_analysis/blob/main/%E9%90%B5%E9%81%94%E5%B0%BC%E8%99%9F%E5%AD%98%E6%B4%BB%E9%A0%90%E6%B8%AC_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wk678XnWecvr",
        "outputId": "7cbecc46-7d71-486d-ab23-40aa8b459511"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.77653631 0.78651685 0.78089888 0.76966292 0.82022472]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def preprocess_dataset(df):\n",
        "    '''\n",
        "    Preprocess the Titanic dataset by handling missing values and removing irrelevant columns.\n",
        "\n",
        "    Parameters:\n",
        "        df (DataFrame): Original dataset.\n",
        "\n",
        "    Returns:\n",
        "        DataFrame: Processed dataset with cleaned and imputed values.\n",
        "    '''\n",
        "    # Fill missing values in the 'Age' column with the mean age\n",
        "    df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
        "\n",
        "    # Fill missing values in the 'Embarked' column with the most frequent value (mode)\n",
        "    df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
        "\n",
        "    # One-Hot Encoding for the 'Sex' and 'Embarked' columns\n",
        "    df = pd.get_dummies(df, columns=['Sex', 'Embarked'])\n",
        "\n",
        "    # Remove irrelevant and categorical columns\n",
        "    df = df.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'])\n",
        "    return df\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/dsindy/kaggle-titanic/master/data/train.csv')\n",
        "df_train = preprocess_dataset(df)\n",
        "\n",
        "columns_X = df_train.drop(columns=['Survived']).columns\n",
        "columns_y = ['Survived']\n",
        "\n",
        "train_X = df_train[columns_X]\n",
        "train_y = df_train[columns_y]\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "log = LogisticRegression(random_state=0, max_iter=3000)\n",
        "scores = cross_val_score(log, train_X, train_y.values.ravel(), cv=5, scoring='accuracy')\n",
        "print(scores)\n"
      ]
    }
  ]
}